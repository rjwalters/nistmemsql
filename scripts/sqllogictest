#!/usr/bin/env bash
#
# SQLLogicTest Unified Tool
#
# One tool for all SQLLogicTest operations:
# - Single file testing (fast iteration)
# - Serial/parallel suite execution
# - Result analysis and reporting
# - Progress tracking with punchlist
#
# Usage:
#   ./scripts/sqllogictest <command> [options]
#
# Commands:
#   test <file>              Test a single file
#   run [--parallel]         Run full test suite
#   punchlist                Generate markdown checklist
#   analyze                  Analyze failure patterns
#   report                   Generate HTML report
#   status                   Show quick summary
#
# Examples:
#   ./scripts/sqllogictest test random/select/slt_good_19.test
#   ./scripts/sqllogictest run --time 60
#   ./scripts/sqllogictest run --parallel --workers 64 --time 3600
#   ./scripts/sqllogictest punchlist
#
# For detailed help on any command:
#   ./scripts/sqllogictest <command> --help

set -euo pipefail

# Get repository root
REPO_ROOT="$(cd "$(dirname "${BASH_SOURCE[0]}")/.." && pwd)"
cd "$REPO_ROOT"

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Print colored output
print_error() { echo -e "${RED}❌ $1${NC}" >&2; }
print_success() { echo -e "${GREEN}✓ $1${NC}"; }
print_warning() { echo -e "${YELLOW}⚠️  $1${NC}"; }
print_info() { echo -e "${BLUE}ℹ $1${NC}"; }

# Check if SQLLogicTest submodule is initialized
check_submodule() {
    local test_dir="third_party/sqllogictest/test"

    if [ ! -d "$test_dir" ] || [ -z "$(ls -A "$test_dir" 2>/dev/null)" ]; then
        print_error "SQLLogicTest submodule not initialized"
        echo ""
        echo "The SQLLogicTest test files are not available. To initialize:"
        echo ""
        echo "  ${GREEN}git submodule update --init --recursive${NC}"
        echo ""
        echo "This will download the test suite (~50MB) into third_party/sqllogictest/"
        echo ""
        exit 1
    fi
}

# Show main help
show_help() {
    cat << 'EOF'
SQLLogicTest Unified Tool

Usage:
  ./scripts/sqllogictest <command> [options]

Commands:
  test <file>              Test a single SQLLogicTest file
  run [options]            Run the full test suite (serial or parallel)
  query [options]          Query test results database (interactive SQL)
  punchlist [options]      Generate markdown checklist of failures
  analyze [options]        Analyze failure patterns
  report [options]         Generate HTML conformance report
  status                   Show quick pass rate summary

Examples:
  # Development (fast iteration on single file)
  ./scripts/sqllogictest test random/select/slt_good_19.test

  # Local testing (serial, quick)
  ./scripts/sqllogictest run --time 60

  # Remote testing (parallel on big machine)
  ssh big-machine
  cd repo && ./scripts/sqllogictest run --parallel --workers 320 --time 3600

  # Analysis and tracking
  ./scripts/sqllogictest analyze
  ./scripts/sqllogictest analyze --top-fixes
  ./scripts/sqllogictest query --preset failed-files
  ./scripts/sqllogictest punchlist
  ./scripts/sqllogictest status

For detailed help on any command:
  ./scripts/sqllogictest <command> --help

Environment Variables:
  SQLLOGICTEST_TIME_BUDGET    Default time budget in seconds
  SQLLOGICTEST_SEED           Random seed for test selection
EOF
}

# Test command: run a single file
cmd_test() {
    if [ $# -eq 0 ] || [ "$1" = "--help" ]; then
        cat << 'EOF'
Test a single SQLLogicTest file

Usage:
  ./scripts/sqllogictest test <file>

Arguments:
  <file>    Path to test file relative to third_party/sqllogictest/test/
            Examples: select1.test, random/select/slt_good_19.test

Examples:
  # Test a specific file
  ./scripts/sqllogictest test select1.test

  # Test a file in subdirectory
  ./scripts/sqllogictest test random/select/slt_good_19.test

  # Quick validation after fixing a bug
  ./scripts/sqllogictest test random/expr/slt_good_113.test

This runs quickly (< 5 seconds) for fast iteration during development.
EOF
        exit 0
    fi

    check_submodule

    local test_file="$1"
    local full_path="third_party/sqllogictest/test/$test_file"

    if [ ! -f "$full_path" ]; then
        print_error "Test file not found: $full_path"
        echo ""
        echo "Available test directories:"
        ls -d third_party/sqllogictest/test/*/ 2>/dev/null | sed 's|third_party/sqllogictest/test/||' || true
        exit 1
    fi

    print_info "Testing: $test_file"
    echo ""

    # Run the test using SQLLOGICTEST_FILES environment variable
    local start_time=$(date +%s)
    local output_log="/tmp/sqllogictest_test_output_$$.log"

    if SQLLOGICTEST_FILES="$full_path" cargo test --release run_sqllogictest_file 2>&1 | tee "$output_log" | grep -q "test result: ok"; then
        local end_time=$(date +%s)
        local elapsed=$((end_time - start_time))
        print_success "Passed (${elapsed}s)"
        rm -f "$output_log"
    else
        local end_time=$(date +%s)
        local elapsed=$((end_time - start_time))
        print_error "Failed (${elapsed}s)"
        echo ""
        echo "Full output saved to: $output_log"
        exit 1
    fi
}

# Run command: execute test suite
cmd_run() {
    local parallel=false
    local workers=""
    local time_budget="${SQLLOGICTEST_TIME_BUDGET:-2400}"
    local per_file_timeout="500"
    local force=false
    local debug_mode=false

    # Parse arguments
    while [[ $# -gt 0 ]]; do
        case $1 in
            --help)
                cat << 'EOF'
Run the SQLLogicTest suite

Usage:
  ./scripts/sqllogictest run [options]

Options:
  --parallel              Run tests in parallel across multiple workers
  --workers N             Number of parallel workers (default: CPU count)
  --time N                Time budget in seconds per worker (default: 300)
  --timeout N             Per-file timeout in seconds (default: 500)
  --debug                 Use debug build (faster compile, 10-15x slower tests)
  --force                 Repopulate work queue with all test files (bypasses smart filtering)

Examples:
  # Serial run (local development, 5 minutes, release mode)
  ./scripts/sqllogictest run

  # Serial with custom time
  ./scripts/sqllogictest run --time 60

  # Debug mode for faster iteration (slow tests!)
  ./scripts/sqllogictest run --debug --time 10

  # Parallel on local machine (uses all CPUs, release mode)
  ./scripts/sqllogictest run --parallel

  # Parallel on remote machine with 320 workers, 1 hour each
  ./scripts/sqllogictest run --parallel --workers 320 --time 3600

  # Custom timeout for slow tests
  ./scripts/sqllogictest run --parallel --workers 8 --timeout 2000

Build Modes:
  - Release (default): 10-15x faster tests, ~60s compile time
  - Debug (--debug): 10-15x slower tests, ~10s compile time
  - ALWAYS use release for CI/benchmarks!

Serial Mode:
  - Runs tests sequentially in a single process
  - Good for local development and debugging
  - Results database in ~/.vibesql/test_results/

Parallel Mode:
  - Spawns multiple workers to test different files concurrently
  - Each worker gets a partition of test files
  - Results merged into target/sqllogictest_cumulative.json
  - Best for remote machines with many vCPUs

Time Budget:
  - Each worker runs for approximately this many seconds
  - Prioritizes previously-failed tests first
  - Tests are randomly sampled to maximize coverage
EOF
                exit 0
                ;;
            --parallel)
                parallel=true
                shift
                ;;
            --workers)
                workers="$2"
                shift 2
                ;;
            --time)
                time_budget="$2"
                shift 2
                ;;
            --timeout)
                per_file_timeout="$2"
                shift 2
                ;;
            --debug)
                debug_mode=true
                shift
                ;;
            --force)
                force=true
                shift
                ;;
            *)
                print_error "Unknown option: $1"
                echo "Run with --help for usage information"
                exit 1
                ;;
        esac
    done

    check_submodule

    if $parallel; then
        # Parallel execution
        if [ -z "$workers" ]; then
            # Default to CPU count
            if command -v nproc &> /dev/null; then
                workers=$(nproc)
            else
                workers=8
            fi
        fi

        print_info "Running parallel test suite"
        echo "Workers: $workers"
        echo "Time budget: ${time_budget}s per worker"
        echo "Build mode: $(if $debug_mode; then echo 'debug (slow tests!)'; else echo 'release (optimized)'; fi)"
        echo ""

        # Build command with optional --debug flag
        local python_args=(
            "--workers" "$workers"
            "--time-budget" "$time_budget"
            "--per-file-timeout" "$per_file_timeout"
        )
        if $debug_mode; then
            python_args+=("--debug")
        fi

        python3 scripts/run_parallel_tests.py "${python_args[@]}"

        print_success "Parallel run complete"
        echo "Results: target/sqllogictest_cumulative.json"

        # Process results into database
        local results_file="target/sqllogictest_cumulative.json"
        if [ -f "$results_file" ]; then
            print_info "Processing results into database..."
            if python3 scripts/process_test_results.py --input "$results_file"; then
                print_success "Database updated: ~/.vibesql/test_results/sqllogictest_results.sql"
            else
                print_warning "Failed to update database (test results still in JSON)"
            fi
        fi
    else
        # Serial execution
        print_info "Running serial test suite"
        echo "Time budget: ${time_budget}s"
        echo "Build mode: $(if $debug_mode; then echo 'debug (slow tests!)'; else echo 'release (optimized)'; fi)"
        echo ""

        # Initialize work queue if --force is specified
        if $force; then
            print_info "Initializing work queue (--force)..."
            python3 -c "
import sys
sys.path.insert(0, 'scripts')
from run_parallel_tests import initialize_work_queue, get_repo_root
from pathlib import Path

repo_root = get_repo_root()
work_queue_dir = Path('/tmp/sqllogictest_work_queue')
count = initialize_work_queue(repo_root, work_queue_dir)
print(f'Work queue initialized with {count} test files')
"
            echo ""
        fi

        # Build with --release unless --debug is specified
        local cargo_args=(
            "test"
            "--package" "vibesql"
            "--test" "sqllogictest_suite"
            "run_sqllogictest_suite"
        )
        if ! $debug_mode; then
            cargo_args=("${cargo_args[@]:0:1}" "--release" "${cargo_args[@]:1}")
        fi

        SQLLOGICTEST_TIME_BUDGET="$time_budget" \
            cargo "${cargo_args[@]}" -- --nocapture

        print_success "Serial run complete"
        echo "Results database: ~/.vibesql/test_results/sqllogictest_results.sql"

        # Process results into database
        local results_file="target/sqllogictest_results.json"
        if [ -f "$results_file" ]; then
            print_info "Processing results into database..."
            if python3 scripts/process_test_results.py --input "$results_file"; then
                print_success "Database updated: ~/.vibesql/test_results/sqllogictest_results.sql"
                echo ""
                echo "Query your results:"
                echo "  ./scripts/query_test_results.py --preset failed-files"
                echo "  ./scripts/query_test_results.py --preset by-category"
            else
                print_warning "Failed to update database (test results still in JSON)"
            fi
        fi
    fi
}

# Punchlist command: generate markdown checklist
cmd_punchlist() {
    local results_file="target/sqllogictest_results.json"
    local output_file="target/sqllogictest_punchlist.md"

    # Parse arguments
    while [[ $# -gt 0 ]]; do
        case $1 in
            --help)
                cat << 'EOF'
Generate markdown punchlist of test results

Usage:
  ./scripts/sqllogictest punchlist [options]

Options:
  --from FILE       Use specific results file (default: target/sqllogictest_results.json)
  --output FILE     Write to specific file (default: target/sqllogictest_punchlist.md)

Examples:
  # Generate punchlist from latest local run
  ./scripts/sqllogictest punchlist

  # Generate from remote parallel run
  ./scripts/sqllogictest punchlist --from target/sqllogictest_cumulative.json

  # Save to custom location
  ./scripts/sqllogictest punchlist --output docs/progress.md

Output Format:
  Generates a markdown file with:
  - Overall pass rate
  - Progress by category
  - Checkboxes for each failing file
  - Grouped by directory
  - Error descriptions

You can check off files as you fix them!
EOF
                exit 0
                ;;
            --from)
                results_file="$2"
                shift 2
                ;;
            --output)
                output_file="$2"
                shift 2
                ;;
            *)
                print_error "Unknown option: $1"
                exit 1
                ;;
        esac
    done

    if [ ! -f "$results_file" ]; then
        print_error "Results file not found: $results_file"
        echo ""
        echo "Run tests first:"
        echo "  ./scripts/sqllogictest run"
        exit 1
    fi

    print_info "Generating punchlist from $results_file"

    # Generate punchlist
    local timestamp=$(date '+%Y-%m-%d %H:%M:%S')

    {
        echo "# SQLLogicTest Punchlist"
        echo ""
        echo "Last updated: $timestamp"
        echo "Source: $results_file"
        echo ""

        # Parse JSON and generate summary
        if command -v jq &> /dev/null && [ -f "$results_file" ]; then
            local total=$(jq -r '.total // 0' "$results_file")
            local passed=$(jq -r '.passed // 0' "$results_file")
            local failed=$(jq -r '.failed // 0' "$results_file")
            local pass_rate=$(jq -r '.pass_rate // 0' "$results_file")

            echo "Pass rate: ${pass_rate}% ($passed/$total files)"
            echo ""

            # Progress by category
            echo "## Progress by Category"
            echo ""
            jq -r '.categories | to_entries[] | select(.value != null) | "- [\(if .value.passed == (.value.total - .value.skipped) then "x" else " " end)] \(.key): \(.value.pass_rate)% (\(.value.passed)/\((.value.total - .value.skipped)))"' "$results_file" 2>/dev/null || echo "No category data available"
            echo ""

            # Failing files
            if [ "$failed" -gt 0 ]; then
                echo "## Failing Files ($failed)"
                echo ""

                # Group by directory
                jq -r '.detailed_failures[]? | "### \(.file_path | split("/")[0])/\n- [ ] \(.file_path) - \(.failures[0].error_message[:100] // "Unknown error")"' "$results_file" 2>/dev/null | head -100
            fi
        else
            echo "⚠️  Could not parse results file (jq not installed or invalid JSON)"
        fi
    } > "$output_file"

    print_success "Punchlist generated: $output_file"
    echo ""
    echo "View it:"
    echo "  cat $output_file"
    echo "  open $output_file  # macOS"
}

# Status command: quick summary
cmd_status() {
    local results_file="target/sqllogictest_results.json"

    # Check for cumulative results too
    if [ -f "target/sqllogictest_cumulative.json" ]; then
        results_file="target/sqllogictest_cumulative.json"
    fi

    if [ ! -f "$results_file" ]; then
        print_warning "No test results found"
        echo ""
        echo "Run tests first:"
        echo "  ./scripts/sqllogictest run"
        exit 1
    fi

    echo "=== SQLLogicTest Status ==="
    echo ""
    echo "Results: $results_file"
    echo ""

    if command -v jq &> /dev/null; then
        local total=$(jq -r '.total // 0' "$results_file")
        local passed=$(jq -r '.passed // 0' "$results_file")
        local failed=$(jq -r '.failed // 0' "$results_file")
        local pass_rate=$(jq -r '.pass_rate // 0' "$results_file")

        echo "Total:      $total files"
        echo "Passed:     $passed"
        echo "Failed:     $failed"
        printf "Pass Rate:  %.1f%%\n" "$pass_rate"
        echo ""

        # Category breakdown
        echo "By Category:"
        jq -r '.categories | to_entries[] | select(.value != null) | "  \(.key): \(.value.pass_rate)% (\(.value.passed)/\((.value.total - .value.skipped)))"' "$results_file" 2>/dev/null
    else
        print_warning "Install jq for formatted output"
        cat "$results_file"
    fi
}

# Analyze command: failure pattern analysis
cmd_analyze() {
    local db_path="$HOME/.vibesql/test_results/sqllogictest_results.sql"
    local show_summary=true
    local show_opportunities=false
    local show_patterns=false
    local show_examples=false
    local show_trend=false
    local generate_report=false
    local output_file="target/sqllogictest_analysis.md"

    # Parse arguments
    while [[ $# -gt 0 ]]; do
        case $1 in
            --help)
                cat << 'EOF'
Analyze SQLLogicTest failure patterns

Usage:
  ./scripts/sqllogictest analyze [options]

Options:
  --top-fixes             Show prioritized list of fix opportunities
  --patterns              Show failure patterns grouped by error type
  --examples              Show example failures for each pattern
  --trend                 Compare recent runs to show progress/regressions
  --report                Generate markdown report to file
  --output FILE           Output file for report (default: target/sqllogictest_analysis.md)

Examples:
  # Show summary with top fix opportunities
  ./scripts/sqllogictest analyze

  # Show detailed failure patterns
  ./scripts/sqllogictest analyze --patterns

  # Generate full markdown report
  ./scripts/sqllogictest analyze --report

  # Show trend analysis
  ./scripts/sqllogictest analyze --trend

Analysis Views:
  The analyze command uses database views to provide insights:
  - failure_patterns: Groups failures by error type
  - fix_opportunities: Prioritizes fixes by impact ratio
  - failure_examples: Shows sample failures for each pattern

Requirements:
  - Test results database at ~/.vibesql/test_results/sqllogictest_results.sql
  - Run tests first with: ./scripts/sqllogictest run
EOF
                exit 0
                ;;
            --top-fixes)
                show_opportunities=true
                show_summary=false
                shift
                ;;
            --patterns)
                show_patterns=true
                show_summary=false
                shift
                ;;
            --examples)
                show_examples=true
                show_summary=false
                shift
                ;;
            --trend)
                show_trend=true
                show_summary=false
                shift
                ;;
            --report)
                generate_report=true
                shift
                ;;
            --output)
                output_file="$2"
                shift 2
                ;;
            *)
                print_error "Unknown option: $1"
                echo "Run with --help for usage information"
                exit 1
                ;;
        esac
    done

    # Check database exists
    if [ ! -f "$db_path" ]; then
        print_error "Test results database not found: $db_path"
        echo ""
        echo "Run tests first to generate database:"
        echo "  ./scripts/sqllogictest run"
        exit 1
    fi

    # If no specific option, show summary with opportunities
    if $show_summary; then
        show_opportunities=true
    fi

    print_info "SQLLogicTest Failure Analysis"
    echo ""

    # Show summary
    if $show_summary || $generate_report; then
        echo "=== Latest Run Summary ==="
        echo ""
        python3 scripts/query_test_results.py --preset analyze-summary --database "$db_path"
        echo ""
    fi

    # Show fix opportunities
    if $show_opportunities || $generate_report; then
        echo "=== Top Fix Opportunities (by impact ratio) ==="
        echo ""
        python3 scripts/query_test_results.py --preset analyze-opportunities --database "$db_path"
        echo ""
        echo "Impact ratio = tests_affected / effort_score"
        echo "Higher ratio = better bang for your buck"
        echo ""
    fi

    # Show patterns
    if $show_patterns || $generate_report; then
        echo "=== Failure Patterns ==="
        echo ""
        python3 scripts/query_test_results.py --preset analyze-patterns --database "$db_path"
        echo ""
    fi

    # Show examples
    if $show_examples || $generate_report; then
        echo "=== Example Failures ==="
        echo ""
        python3 scripts/query_test_results.py --preset analyze-examples --database "$db_path"
        echo ""
    fi

    # Show trend
    if $show_trend || $generate_report; then
        echo "=== Recent Runs (trend analysis) ==="
        echo ""
        python3 scripts/query_test_results.py --preset progress --database "$db_path"
        echo ""
    fi

    # Generate report
    if $generate_report; then
        print_info "Generating markdown report..."

        {
            echo "# SQLLogicTest Failure Analysis"
            echo ""
            echo "Generated: $(date '+%Y-%m-%d %H:%M:%S')"
            echo ""

            echo "## Latest Run Summary"
            echo ""
            echo '```'
            python3 scripts/query_test_results.py --preset analyze-summary --database "$db_path" 2>/dev/null
            echo '```'
            echo ""

            echo "## Top Fix Opportunities"
            echo ""
            echo "Prioritized by impact ratio (tests_affected / effort_score):"
            echo ""
            echo '```'
            python3 scripts/query_test_results.py --preset analyze-opportunities --database "$db_path" 2>/dev/null
            echo '```'
            echo ""

            echo "## Failure Patterns"
            echo ""
            echo '```'
            python3 scripts/query_test_results.py --preset analyze-patterns --database "$db_path" 2>/dev/null
            echo '```'
            echo ""

            echo "## Example Failures"
            echo ""
            echo '```'
            python3 scripts/query_test_results.py --preset analyze-examples --database "$db_path" 2>/dev/null
            echo '```'
            echo ""

            echo "## Trend Analysis"
            echo ""
            echo '```'
            python3 scripts/query_test_results.py --preset progress --database "$db_path" 2>/dev/null
            echo '```'
            echo ""

            echo "---"
            echo ""
            echo "For detailed queries, use:"
            echo "  ./scripts/sqllogictest query --preset <preset-name>"
            echo "  ./scripts/sqllogictest analyze --<option>"
        } > "$output_file"

        print_success "Report generated: $output_file"
        echo ""
        echo "View it:"
        echo "  cat $output_file"
        echo "  open $output_file  # macOS"
        echo ""
    fi

    # Show helpful next steps
    if ! $generate_report; then
        echo "Run './scripts/sqllogictest analyze --help' for more options"
    fi
}

# Main command router
main() {
    if [ $# -eq 0 ] || [ "$1" = "--help" ] || [ "$1" = "-h" ]; then
        show_help
        exit 0
    fi

    local command="$1"
    shift

    case "$command" in
        test)
            cmd_test "$@"
            ;;
        run)
            cmd_run "$@"
            ;;
        punchlist)
            cmd_punchlist "$@"
            ;;
        status)
            cmd_status "$@"
            ;;
        query)
            # Pass through to query script
            python3 scripts/query_test_results.py "$@"
            ;;
        analyze)
            cmd_analyze "$@"
            ;;
        report)
            print_warning "Command 'report' not yet implemented"
            echo "Coming soon! Track progress at: https://github.com/rjwalters/vibesql/issues/973"
            echo ""
            echo "For now, use: ./scripts/sqllogictest analyze --report"
            exit 1
            ;;
        *)
            print_error "Unknown command: $command"
            echo ""
            echo "Run './scripts/sqllogictest --help' for usage"
            exit 1
            ;;
    esac
}

main "$@"
