name: Boost SQLLogicTest Coverage

on:
  workflow_dispatch:
    inputs:
      time_budget:
        description: 'Time budget in seconds (default: 300 = 5 minutes)'
        required: false
        default: '300'
        type: string
      run_count:
        description: 'Number of sequential test runs (default: 1)'
        required: false
        default: '1'
        type: string
      parallel_runners:
        description: 'Number of parallel runners (default: 1, max: 10)'
        required: false
        default: '1'
        type: string
  # Automatic hourly boost: 10 parallel workers for 30 minutes each (only if work remains)
  schedule:
    - cron: '0 * * * *'  # Every hour

# Sets permissions for GitHub Pages deployment
permissions:
  contents: read
  pages: write
  id-token: write

jobs:
  check-remaining-work:
    name: Check if there are untested files
    runs-on: ubuntu-latest
    # Only run this check for scheduled (cron) runs
    if: github.event_name == 'schedule'
    outputs:
      should_boost: ${{ steps.check.outputs.should_boost }}

    steps:
      - name: Download historical results
        id: check
        run: |
          echo "Checking if there are untested SQLLogicTest files..."

          # Default to boosting if we can't determine status
          SHOULD_BOOST="true"

          # Download cumulative results
          if curl -sL https://rjwalters.github.io/vibesql/badges/sqllogictest_cumulative.json \
            -o cumulative.json 2>/dev/null; then

            if jq empty cumulative.json 2>/dev/null; then
              COVERAGE=$(jq -r '.summary.coverage_rate // 0' cumulative.json)
              TESTED=$(jq -r '.summary.total_tested_files // 0' cumulative.json)
              AVAILABLE=$(jq -r '.summary.total_available_files // 0' cumulative.json)

              echo "Current coverage: ${COVERAGE}%"
              echo "Files tested: ${TESTED}/${AVAILABLE}"

              # Skip if coverage is 100%
              if [ "$COVERAGE" == "100.0" ] || [ "$TESTED" == "$AVAILABLE" ]; then
                echo "âœ“ Coverage is already 100% - no work remaining!"
                SHOULD_BOOST="false"
              else
                REMAINING=$((AVAILABLE - TESTED))
                echo "ðŸ“Š Found $REMAINING untested files - boost is needed"
                SHOULD_BOOST="true"
              fi
            else
              echo "âš ï¸  Invalid JSON - will run boost to establish baseline"
            fi
          else
            echo "âš ï¸  No historical data found - will run boost to establish baseline"
          fi

          echo "should_boost=$SHOULD_BOOST" >> $GITHUB_OUTPUT

  boost-coverage:
    name: Boost SQLLogicTest Coverage (Runner ${{ matrix.runner_id }})
    runs-on: ubuntu-latest
    # For manual runs: always run
    # For scheduled runs: only run if check-remaining-work says there's work to do
    needs: [check-remaining-work]
    if: |
      always() &&
      (github.event_name == 'workflow_dispatch' ||
       (github.event_name == 'schedule' && needs.check-remaining-work.outputs.should_boost == 'true'))
    strategy:
      fail-fast: false
      matrix:
        runner_id: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]

    steps:
      - name: Check if runner should execute
        id: should_run
        run: |
          # For scheduled runs: use 10 parallel runners
          # For manual runs: use the specified number (default 1)
          if [ "${{ github.event_name }}" == "schedule" ]; then
            PARALLEL_RUNNERS=10
          else
            PARALLEL_RUNNERS=${{ github.event.inputs.parallel_runners || '1' }}
          fi

          if [ ${{ matrix.runner_id }} -le $PARALLEL_RUNNERS ]; then
            echo "run=true" >> $GITHUB_OUTPUT
          else
            echo "run=false" >> $GITHUB_OUTPUT
          fi

      - name: Checkout repository
        if: steps.should_run.outputs.run == 'true'
        uses: actions/checkout@v4
        with:
          submodules: recursive

      - name: Setup Rust
        if: steps.should_run.outputs.run == 'true'
        uses: ./.github/actions/setup-rust
        with:
          cache-key-suffix: boost

      - name: Setup Python
        if: steps.should_run.outputs.run == 'true'
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Download historical SQLLogicTest results
        if: steps.should_run.outputs.run == 'true'
        continue-on-error: true
        run: |
          echo "Downloading historical SQLLogicTest results..."
          mkdir -p target

          # Download and validate JSON
          if curl -sL https://rjwalters.github.io/vibesql/badges/sqllogictest_cumulative.json \
            -o sqllogictest_cumulative.json 2>/dev/null; then

            # Check if it's valid JSON (not an HTML error page)
            if jq empty sqllogictest_cumulative.json 2>/dev/null; then
              echo "âœ“ Downloaded existing cumulative results"
              echo ""
              echo "Baseline summary:"
              jq '.summary' sqllogictest_cumulative.json || echo "{}"
              echo ""
              echo "Already tested files:"
              PASSED_COUNT=$(jq -r '.tested_files.passed | length' sqllogictest_cumulative.json)
              FAILED_COUNT=$(jq -r '.tested_files.failed | length' sqllogictest_cumulative.json)
              TOTAL_TESTED=$((PASSED_COUNT + FAILED_COUNT))
              echo "  Total already tested: $TOTAL_TESTED (Passed: $PASSED_COUNT, Failed: $FAILED_COUNT)"
              echo "  This means all ${{ matrix.runner_id }} runners will prioritize the SAME untested files"
              echo ""
              cp sqllogictest_cumulative.json target/sqllogictest_historical.json
            else
              echo "Downloaded file is not valid JSON (likely 404 page) - starting fresh"
              echo '{}' > target/sqllogictest_historical.json
            fi
          else
            echo "No existing cumulative results found - starting fresh"
            echo '{}' > target/sqllogictest_historical.json
          fi

      - name: Run SQLLogicTest boost (multiple runs)
        if: steps.should_run.outputs.run == 'true'
        run: |
          # For scheduled runs: use 30 minutes (1800 seconds) to allow runners to reach more diverse files
          # For manual runs: use the specified time (default 5 minutes)
          if [ "${{ github.event_name }}" == "schedule" ]; then
            TIME_BUDGET="1800"
            RUN_COUNT="1"
          else
            TIME_BUDGET="${{ github.event.inputs.time_budget || '300' }}"
            RUN_COUNT="${{ github.event.inputs.run_count || '1' }}"
          fi

          echo "=== Boost Configuration ==="
          echo "Time budget per run: ${TIME_BUDGET}s"
          echo "Number of runs: ${RUN_COUNT}"
          echo ""

          mkdir -p target/boost_runs

          RUNNER_ID="${{ matrix.runner_id }}"

          # Determine total workers based on trigger
          if [ "${{ github.event_name }}" == "schedule" ]; then
            TOTAL_WORKERS=10
          else
            TOTAL_WORKERS=${{ github.event.inputs.parallel_runners || '1' }}
          fi

          for i in $(seq 1 $RUN_COUNT); do
            echo ""
            echo "=== Runner $RUNNER_ID - Boost Run $i of $RUN_COUNT ==="

            # Use shared timestamp as seed so all workers shuffle files the same way
            # Then each worker selects their partition based on worker ID
            SEED=$(date +%s)
            echo "Using shared seed: $SEED (all workers use same seed)"
            echo "Worker configuration: $RUNNER_ID of $TOTAL_WORKERS workers"
            echo ""

            # Run tests with worker partitioning
            echo "=== Starting test run with file partitioning ==="
            SQLLOGICTEST_SEED=$SEED \
            SQLLOGICTEST_WORKER_ID=$RUNNER_ID \
            SQLLOGICTEST_TOTAL_WORKERS=$TOTAL_WORKERS \
            timeout $((TIME_BUDGET + 30)) \
              cargo test --test sqllogictest_suite --release -- --nocapture 2>&1 | \
              tee target/boost_runs/run_${RUNNER_ID}_${i}.log | \
              python3 scripts/analyze_sqllogictest.py

            echo ""
            echo "=== Test run completed ==="
            echo "Files tested in this run (from log):"
            grep -E "^(âœ“|âœ—) " target/boost_runs/run_${RUNNER_ID}_${i}.log | head -20 || echo "No test results found"
            echo ""

            # Save this run's results
            if [ -f target/sqllogictest_analysis.json ]; then
              cp target/sqllogictest_analysis.json target/boost_runs/analysis_${RUNNER_ID}_${i}.json
              echo "âœ“ Saved analysis for run $i"
            fi

            # Merge with cumulative results after each run
            if [ -f target/sqllogictest_analysis.json ]; then
              echo "Merging run $i with cumulative results..."
              python3 scripts/merge_sqllogictest_results.py \
                target/sqllogictest_analysis.json \
                target/sqllogictest_historical.json \
                target/sqllogictest_cumulative_new.json

              # Update historical for next iteration
              if [ -f target/sqllogictest_cumulative_new.json ]; then
                cp target/sqllogictest_cumulative_new.json target/sqllogictest_historical.json
                cp target/sqllogictest_cumulative_new.json target/sqllogictest_cumulative.json
                echo "âœ“ Updated cumulative results"
                cat target/sqllogictest_cumulative.json | jq '.summary'
              fi
            fi

            echo ""
          done

          echo ""
          echo "=== Boost Complete ==="
          if [ -f target/sqllogictest_cumulative.json ]; then
            echo "Final cumulative results:"
            cat target/sqllogictest_cumulative.json | jq '.summary'
          fi
        env:
          SQLLOGICTEST_TIME_BUDGET: ${{ github.event.inputs.time_budget || '300' }}

      - name: Generate boost summary
        if: always() && steps.should_run.outputs.run == 'true'
        run: |
          # Determine parallel runners and time budget based on trigger
          if [ "${{ github.event_name }}" == "schedule" ]; then
            PARALLEL_RUNNERS=10
            TIME_BUDGET=1800
            RUN_COUNT=1
            TRIGGER_TYPE="Scheduled (hourly cron)"
          else
            PARALLEL_RUNNERS=${{ github.event.inputs.parallel_runners || '1' }}
            TIME_BUDGET=${{ github.event.inputs.time_budget || '300' }}
            RUN_COUNT=${{ github.event.inputs.run_count || '1' }}
            TRIGGER_TYPE="Manual"
          fi

          echo "# SQLLogicTest Boost Run Summary (Runner ${{ matrix.runner_id }})" > boost_summary.md
          echo "" >> boost_summary.md
          echo "**Trigger:** $TRIGGER_TYPE" >> boost_summary.md
          echo "**Triggered by:** ${{ github.actor }}" >> boost_summary.md
          echo "**Time:** $(date -u)" >> boost_summary.md
          echo "**Runner ID:** ${{ matrix.runner_id }} / $PARALLEL_RUNNERS" >> boost_summary.md
          echo "**Time budget per run:** ${TIME_BUDGET}s" >> boost_summary.md
          echo "**Number of runs:** $RUN_COUNT" >> boost_summary.md
          echo "" >> boost_summary.md

          if [ -f target/sqllogictest_cumulative.json ]; then
            echo "## Cumulative Results" >> boost_summary.md
            echo "" >> boost_summary.md
            echo '```json' >> boost_summary.md
            cat target/sqllogictest_cumulative.json | jq '.summary' >> boost_summary.md
            echo '```' >> boost_summary.md
            echo "" >> boost_summary.md
            echo "**Coverage:** $(jq -r '.summary.coverage_rate' target/sqllogictest_cumulative.json)%" >> boost_summary.md
            echo "**Pass Rate:** $(jq -r '.summary.pass_rate' target/sqllogictest_cumulative.json)%" >> boost_summary.md
            echo "**Files Tested:** $(jq -r '.summary.total_tested_files' target/sqllogictest_cumulative.json) / $(jq -r '.summary.total_available_files' target/sqllogictest_cumulative.json)" >> boost_summary.md

            if [ -f target/sqllogictest_cumulative.json ]; then
              NEW_TESTED=$(jq -r '.merge_info.new_files_tested // 0' target/sqllogictest_cumulative.json)
              echo "**New files tested this boost:** $NEW_TESTED" >> boost_summary.md
            fi
          fi

          cat boost_summary.md

      - name: Upload boost results
        uses: actions/upload-artifact@v4
        if: always() && steps.should_run.outputs.run == 'true'
        with:
          name: boost-results-${{ github.run_number }}-runner-${{ matrix.runner_id }}
          path: |
            target/sqllogictest_cumulative.json
            target/sqllogictest_analysis.json
            target/boost_runs/*.json
            boost_summary.md
          retention-days: 90

  # Aggregation job: Collects results from all parallel runners
  aggregate-results:
    name: Aggregate Results
    runs-on: ubuntu-latest
    needs: boost-coverage
    if: always() && github.ref == 'refs/heads/main'

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Download all runner artifacts for this run
        uses: actions/download-artifact@v4
        with:
          pattern: boost-results-${{ github.run_number }}-runner-*
          path: artifacts/
          merge-multiple: false

      - name: Download historical SQLLogicTest results
        continue-on-error: true
        run: |
          echo "Downloading historical cumulative results from gh-pages..."
          mkdir -p aggregated

          if curl -sL https://rjwalters.github.io/vibesql/badges/sqllogictest_cumulative.json \
            -o aggregated/sqllogictest_historical.json 2>/dev/null; then
            if jq empty aggregated/sqllogictest_historical.json 2>/dev/null; then
              echo "âœ“ Downloaded existing cumulative results"
              jq '.summary' aggregated/sqllogictest_historical.json
            else
              echo "Downloaded file is not valid JSON - starting fresh"
              echo '{}' > aggregated/sqllogictest_historical.json
            fi
          else
            echo "No existing cumulative results found - starting fresh"
            echo '{}' > aggregated/sqllogictest_historical.json
          fi

      - name: Merge all runner results
        run: |
          echo "=== Aggregating Results from All Runners ==="
          echo ""

          # Start with historical data
          cp aggregated/sqllogictest_historical.json aggregated/sqllogictest_merged.json

          # Find all runner result files
          RUNNER_FILES=$(find artifacts -name "sqllogictest_cumulative.json" | sort)
          RUNNER_COUNT=$(echo "$RUNNER_FILES" | wc -l | tr -d ' ')

          echo "Found $RUNNER_COUNT runner result files"
          echo ""

          # Merge each runner's results
          RUNNER_NUM=1
          for result_file in $RUNNER_FILES; do
            echo "Merging runner $RUNNER_NUM results..."

            python3 scripts/merge_sqllogictest_results.py \
              "$result_file" \
              aggregated/sqllogictest_merged.json \
              aggregated/sqllogictest_merged_new.json

            if [ -f aggregated/sqllogictest_merged_new.json ]; then
              mv aggregated/sqllogictest_merged_new.json aggregated/sqllogictest_merged.json
              echo "âœ“ Merged runner $RUNNER_NUM"
            fi

            RUNNER_NUM=$((RUNNER_NUM + 1))
          done

          echo ""
          echo "=== Final Aggregated Results ==="
          jq '.summary' aggregated/sqllogictest_merged.json

      - name: Upload aggregated results artifact
        uses: actions/upload-artifact@v4
        with:
          name: boost-aggregated-results
          path: aggregated/sqllogictest_merged.json
          retention-days: 90

  # Deploy job: Calls centralized deployment workflow
  deploy:
    needs: aggregate-results
    if: always() && needs.aggregate-results.result == 'success' && github.ref == 'refs/heads/main'
    uses: ./.github/workflows/deploy-pages.yml
    permissions:
      contents: read
      pages: write
      id-token: write
    with:
      artifact-name: boost-aggregated-results
      rebuild-web-demo: true  # Boost needs to rebuild web demo to avoid download issues
