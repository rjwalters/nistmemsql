name: CI and Deploy

on:
  push:
    branches: [main]
  workflow_dispatch:

# Sets permissions for GitHub Pages deployment
permissions:
  contents: read
  pages: write
  id-token: write

# Allow only one concurrent deployment
concurrency:
  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}
  cancel-in-progress: true

jobs:
  # ============================================================================
  # JOB 1: Build and Test
  # ============================================================================
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          submodules: recursive

      - name: Setup Rust
        uses: dtolnay/rust-toolchain@stable

      - name: Cache Rust dependencies
        uses: Swatinem/rust-cache@v2
        with:
          shared-key: "rust-ci-cache"

      - name: Run unit tests
        run: cargo test --release --lib

      - name: Run sqltest conformance suite
        run: cargo test --test sqltest_conformance --release -- --nocapture
        continue-on-error: true

      - name: Run SQLLogicTest suite with analysis
        run: |
          timeout 120 cargo test --test sqllogictest_suite --release -- --nocapture 2>&1 | tee target/sqllogictest_raw.log | python3 scripts/analyze_sqllogictest.py
        continue-on-error: true

      - name: Upload test results
        uses: actions/upload-artifact@v4
        with:
          name: test-results
          path: |
            target/sqltest_results.json
            target/sqllogictest_results.json
            target/sqllogictest_analysis.json
            target/sqllogictest_analysis.md
            target/sqllogictest_raw.log
          retention-days: 90

  # ============================================================================
  # JOB 2: Benchmarks (depends on test)
  # ============================================================================
  benchmark:
    runs-on: ubuntu-latest
    needs: test
    steps:
      - uses: actions/checkout@v4
        with:
          submodules: recursive

      - name: Setup Rust
        uses: dtolnay/rust-toolchain@stable

      - name: Cache Rust dependencies
        uses: Swatinem/rust-cache@v2
        with:
          shared-key: "rust-ci-cache"

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install uv
        uses: astral-sh/setup-uv@v3

      - name: Build and install Python bindings
        run: |
          uv pip install --system maturin
          cd crates/python-bindings
          maturin build --release
          uv pip install --system ../../target/wheels/nistmemsql_py-*.whl

      - name: Install benchmark dependencies
        run: |
          grep -v "^nistmemsql" benchmarks/requirements.txt > /tmp/requirements-ci.txt
          uv pip install --system -r /tmp/requirements-ci.txt

      - name: Run benchmarks
        working-directory: benchmarks
        run: |
          pytest test_insert.py test_update.py test_delete.py test_select.py test_aggregates.py \
            --benchmark-only \
            --benchmark-json=../benchmark_results.json \
            --benchmark-min-rounds=3 \
            --benchmark-warmup=off

      - name: Upload benchmark results
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-results
          path: benchmark_results.json
          retention-days: 90

      - name: Display results summary
        run: |
          echo "## Benchmark Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          python benchmarks/format_results.py benchmark_results.json >> $GITHUB_STEP_SUMMARY

  # ============================================================================
  # JOB 3: Deploy (depends on test and benchmark)
  # ============================================================================
  deploy:
    runs-on: ubuntu-latest
    needs: [test, benchmark]

    steps:
      - uses: actions/checkout@v4
        with:
          submodules: recursive

      - name: Setup Rust
        uses: dtolnay/rust-toolchain@stable
        with:
          targets: wasm32-unknown-unknown

      - name: Cache Rust dependencies
        uses: Swatinem/rust-cache@v2
        with:
          shared-key: "rust-ci-cache"

      - name: Install wasm-pack
        run: curl https://rustwasm.github.io/wasm-pack/installer/init.sh -sSf | sh

      - name: Build WASM bindings
        working-directory: crates/wasm-bindings
        run: wasm-pack build --target web --release

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: web-demo/package-lock.json

      - name: Install and build web demo
        working-directory: web-demo
        run: |
          npm ci
          npm run build

      # Download artifacts from previous jobs
      - name: Download test results
        uses: actions/download-artifact@v4
        with:
          name: test-results
          path: target

      - name: Download benchmark results
        uses: actions/download-artifact@v4
        with:
          name: benchmark-results

      - name: Verify downloaded artifacts
        run: |
          echo "=== Checking downloaded benchmark artifacts ==="
          ls -la benchmark_results.json || echo "ERROR: benchmark_results.json not found!"
          echo "=== Checking test artifacts ==="
          ls -la target/sqltest_results.json || echo "ERROR: sqltest_results.json not found!"
          ls -la target/sqllogictest_results.json || echo "ERROR: sqllogictest_results.json not found!"

      - name: Download benchmark history from gh-pages
        continue-on-error: true
        run: |
          if curl -sL https://rjwalters.github.io/nistmemsql/benchmarks/benchmark_history.json \
            -o benchmark_history.json; then
            echo "Downloaded existing benchmark history"
          else
            echo "No existing history found - will create new file"
            # Don't create the file if it doesn't exist
          fi

      - name: Update benchmark history
        run: |
          python benchmarks/update_history.py \
            benchmark_results.json \
            benchmark_history.json \
            ${{ github.sha }}
        continue-on-error: true

      # Generate badges
      - name: Generate badge JSON
        run: |
          mkdir -p badges

          # Extract pass rate from sqltest results
          if [ -f target/sqltest_results.json ]; then
            PASS_RATE=$(jq -r '.pass_rate // "0"' target/sqltest_results.json | xargs printf "%.1f")
          else
            PASS_RATE="0.0"
          fi

          # Determine badge color
          if (( $(echo "$PASS_RATE >= 80" | bc -l) )); then
            COLOR="brightgreen"
          elif (( $(echo "$PASS_RATE >= 60" | bc -l) )); then
            COLOR="green"
          elif (( $(echo "$PASS_RATE >= 40" | bc -l) )); then
            COLOR="yellow"
          elif (( $(echo "$PASS_RATE >= 20" | bc -l) )); then
            COLOR="orange"
          else
            COLOR="red"
          fi

          # Create SQL:1999 badge JSON
          cat > badges/sql1999-conformance.json <<JSON
          {
            "schemaVersion": 1,
            "label": "SQL:1999",
            "message": "${PASS_RATE}%",
            "color": "$COLOR"
          }
          JSON

          echo "Generated SQL:1999 badge: ${PASS_RATE}% ($COLOR)"

          # Extract pass rate from SQLLogicTest results
          if [ -f target/sqllogictest_results.json ]; then
            SLT_PASS_RATE=$(jq -r '.pass_rate // "0"' target/sqllogictest_results.json | xargs printf "%.1f")
          else
            SLT_PASS_RATE="0.0"
          fi

          # Determine SQLLogicTest badge color
          if (( $(echo "$SLT_PASS_RATE >= 80" | bc -l) )); then
            SLT_COLOR="brightgreen"
          elif (( $(echo "$SLT_PASS_RATE >= 60" | bc -l) )); then
            SLT_COLOR="green"
          elif (( $(echo "$SLT_PASS_RATE >= 40" | bc -l) )); then
            SLT_COLOR="yellow"
          elif (( $(echo "$SLT_PASS_RATE >= 20" | bc -l) )); then
            SLT_COLOR="orange"
          else
            SLT_COLOR="red"
          fi

          # Create SQLLogicTest badge JSON
          cat > badges/sqllogictest.json <<JSON
          {
            "schemaVersion": 1,
            "label": "SQLLogicTest",
            "message": "${SLT_PASS_RATE}%",
            "color": "$SLT_COLOR"
          }
          JSON

          echo "Generated SQLLogicTest badge: ${SLT_PASS_RATE}% ($SLT_COLOR)"

          # Copy results
          [ -f target/sqltest_results.json ] && cp target/sqltest_results.json badges/
          [ -f target/sqllogictest_results.json ] && cp target/sqllogictest_results.json badges/
          [ -f target/sqllogictest_analysis.json ] && cp target/sqllogictest_analysis.json badges/
          [ -f target/sqllogictest_analysis.md ] && cp target/sqllogictest_analysis.md badges/
          [ -f benchmark_results.json ] && cp benchmark_results.json badges/
          [ -f benchmark_history.json ] && cp benchmark_history.json badges/

      # Prepare deployment
      - name: Prepare deployment
        run: |
          mkdir -p deploy
          cp -r web-demo/dist/* deploy/
          mkdir -p deploy/benchmarks
          cp -r badges deploy/badges

          # Copy benchmark files with verification
          if [ -f badges/benchmark_results.json ]; then
            cp badges/benchmark_results.json deploy/benchmarks/
            echo "✓ Copied benchmark_results.json to deploy/benchmarks/"
          else
            echo "⚠️  WARNING: badges/benchmark_results.json not found!"
          fi

          if [ -f badges/benchmark_history.json ]; then
            cp badges/benchmark_history.json deploy/benchmarks/
            echo "✓ Copied benchmark_history.json to deploy/benchmarks/"
          else
            echo "⚠️  WARNING: badges/benchmark_history.json not found!"
          fi

          # Copy SQLLogicTest analysis files
          if [ -f badges/sqllogictest_analysis.json ]; then
            cp badges/sqllogictest_analysis.json deploy/badges/
            echo "✓ Copied sqllogictest_analysis.json to deploy/badges/"
          fi

          if [ -f badges/sqllogictest_analysis.md ]; then
            cp badges/sqllogictest_analysis.md deploy/badges/
            echo "✓ Copied sqllogictest_analysis.md to deploy/badges/"
          fi

          echo ""
          echo "=== Deployment structure ==="
          ls -la deploy/
          echo ""
          echo "=== Badges directory ==="
          ls -la deploy/badges/ || echo "No badges directory"
          echo ""
          echo "=== Benchmarks directory ==="
          ls -la deploy/benchmarks/ || echo "No benchmarks directory"

      # Deploy to GitHub Pages
      - name: Setup Pages
        uses: actions/configure-pages@v4

      - name: Upload Pages artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: './deploy'

      - name: Deploy to GitHub Pages
        uses: actions/deploy-pages@v4
